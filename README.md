# web-scraping

## General Presentation

This repository includes the first part of my second-year internship at ENSAE (National School of Statistics and Economic Administration), which I carried out at INRAE (National Research Institute for Agriculture, Food and the Environment) over a 1-month period.

## Planning

The initial planning did not include any hard deadlines, and left room for flexibility. Here are the main stages:
- study the Oqali database, understand how it is obtained and the different variables,
- Study of the architecture of different sites (protection, dynamic or static, URL path, available information, etc.),
- Web-scraping implementation,
- Dockerization and commissioning on INRAE server.

The foreseeable difficulties were :
- Access to different sites with protection,
- Different approach for static and dynamic sites,
- Finding a pattern to scrape the right URLs.

## Contributions

This part of the internship is a first for INRAE, which would like to automate the addition of information to its database. There was no previous work on the same theme at INRAE.

## Tools and technologies

Python is an interpreted, multi-paradigm, multi-platform programming language. It has the advantage of custom libraries, such as Scrapy, widely used in Web-scraping. The language has extensive documentation and a large community on the Internet, making it an invaluable resource in case of bugs or questions. The working environment was Visual Studio Code, a free, open source Python distribution dedicated to data science. We used a template called CookieCutter to organize the code according to the stages of our algorithm. Scrapy is a free Python library for Web-Scrawling and Web-Scraping.

## Context 



## Project hierarchy





## Technical Specifications

## Taking a step back



## Conclusion